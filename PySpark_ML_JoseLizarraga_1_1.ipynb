{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTPC0sYdruuEx+jn/6fo3e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/currencyfxjle/PySpark_Models_Evaluation/blob/main/PySpark_ML_JoseLizarraga_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Machine Learning**"
      ],
      "metadata": {
        "id": "5bVemlfec0Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGaEH4gXa9uO",
        "outputId": "cd26a156-acf6-442f-886d-2d2820f8d656"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=2f9f3b8f32952945980a2b8a3482ed9c83693be2354cbfd7656b9719c731d2b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importes PySpark**"
      ],
      "metadata": {
        "id": "Ify3M5AKpgu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, Binarizer\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Inicia una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"PollutionAnalysisEnhanced\").getOrCreate()\n",
        "\n",
        "# Carga los datos\n",
        "df = spark.read.csv(\"/content/MonterreyPollutionData.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "qCTlAvzUmt3A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exclusión de Contaminantes como Variables Independientes:** Las variables CO, NO, NO2, NOX, O3, PM10, y PM2_5 se consideran contaminantes, por lo que los excluiremos de nuestras variables independientes. Nos centraremos en PRS (presión atmosférica), RAINF (lluvia), RH (humedad relativa), SR (radiación solar), TOUT (temperatura exterior), WSR (velocidad del viento), y WDV (dirección del viento)."
      ],
      "metadata": {
        "id": "L-oV-OM3gimd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Asumiendo que 'df' ya está definido y seleccionado correctamente\n",
        "\n",
        "# Lista de variables no contaminantes más la variable objetivo\n",
        "featureCols = ['PRS', 'RAINF', 'RH', 'SR', 'TOUT', 'WSR', 'WDV', 'PM10']\n",
        "\n",
        "# Calcula y muestra la correlación de Pearson para cada par de variables\n",
        "for i in range(len(featureCols)):\n",
        "    for j in range(i+1, len(featureCols)):\n",
        "        correlation = df.stat.corr(featureCols[i], featureCols[j])\n",
        "        print(f\"Correlation between {featureCols[i]} and {featureCols[j]}: {correlation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0koFgNyOf_R0",
        "outputId": "116a8c11-3b06-4c52-b052-8b16bd71555b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between PRS and RAINF: 0.005096307074890743\n",
            "Correlation between PRS and RH: 0.12850916067491472\n",
            "Correlation between PRS and SR: -0.14052127985403953\n",
            "Correlation between PRS and TOUT: -0.6611628057429934\n",
            "Correlation between PRS and WSR: -0.2160316856488538\n",
            "Correlation between PRS and WDV: 0.13427310751210747\n",
            "Correlation between PRS and PM10: -0.07659701332290413\n",
            "Correlation between RAINF and RH: 0.06550695949155035\n",
            "Correlation between RAINF and SR: -0.0359759430878159\n",
            "Correlation between RAINF and TOUT: -0.029789121239439297\n",
            "Correlation between RAINF and WSR: -0.015194824899400989\n",
            "Correlation between RAINF and WDV: 0.003243082223413366\n",
            "Correlation between RAINF and PM10: -0.02553238816521358\n",
            "Correlation between RH and SR: -0.4599576161421162\n",
            "Correlation between RH and TOUT: -0.5509104512638529\n",
            "Correlation between RH and WSR: -0.4149172138477301\n",
            "Correlation between RH and WDV: 0.06847707860565926\n",
            "Correlation between RH and PM10: -0.10313336817644697\n",
            "Correlation between SR and TOUT: 0.45622603017232166\n",
            "Correlation between SR and WSR: 0.2021808766789149\n",
            "Correlation between SR and WDV: -0.10112286346891934\n",
            "Correlation between SR and PM10: 0.0552198582921118\n",
            "Correlation between TOUT and WSR: 0.4657961497910708\n",
            "Correlation between TOUT and WDV: -0.26496196233343056\n",
            "Correlation between TOUT and PM10: 0.05994127919050276\n",
            "Correlation between WSR and WDV: -0.14934754188059554\n",
            "Correlation between WSR and PM10: -0.1396383678723885\n",
            "Correlation between WDV and PM10: 0.06329837214486915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo y Evaluacion de Datos**"
      ],
      "metadata": {
        "id": "wCSmf9x-pwSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**La binarización es una técnica de preprocesamiento utilizada para convertir** **datos numéricos en categorías binarias (0 o 1) basadas en un umbral.**\n",
        "\n",
        "**Simplificación del Problema:** Convierte un problema de regresión en un problema de clasificación binaria. La regresión implica predecir un valor numérico continuo, mientras que la clasificación se centra en predecir a qué categoría pertenece una observación.\n",
        "\n",
        "**Relevancia Práctica:** En muchos casos, especialmente en la salud pública o la política ambiental, es más relevante saber si los niveles de contaminación superan ciertos umbrales críticos que requieren acción o atención, en lugar de conocer el valor exacto de contaminación.\n",
        "\n",
        "**Mejora de la Modelización:** Para algunos conjuntos de datos, especialmente aquellos con relaciones no lineales complejas o con valores extremos, la clasificación puede ser más robusta y ofrecer mejor rendimiento predictivo en comparación con la modelización de regresión.\n",
        "\n",
        "**Evaluación de Modelos:** Permite utilizar métricas de evaluación específicas para clasificación, como la precisión, el recall, el F1 score y el AUC (Área Bajo la Curva ROC), que pueden proporcionar una visión más clara del rendimiento del modelo en tareas de clasificación que las métricas típicamente usadas en regresión."
      ],
      "metadata": {
        "id": "ZHcu_COlyIyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimento: Ajustando el Umbral de Binarización**\n",
        "\n",
        "# Cambia el valor de threshold para experimentar\n",
        "binarizer = Binarizer(threshold=20, inputCol=\"PM10\", outputCol=\"label\")"
      ],
      "metadata": {
        "id": "yMjYhIgGy9nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import SparkSession\n",
        "# from pyspark.ml.feature import VectorAssembler, StandardScaler, Binarizer\n",
        "# from pyspark.ml.regression import LinearRegression\n",
        "# from pyspark.ml.classification import RandomForestClassifier\n",
        "# from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "# from pyspark.ml import Pipeline\n",
        "# from pyspark.sql.functions import col\n",
        "# from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Inicia una sesión de Spark\n",
        "# spark = SparkSession.builder.appName(\"PollutionAnalysisEnhanced\").getOrCreate()\n",
        "\n",
        "# Carga los datos\n",
        "# df = spark.read.csv(\"/content/MonterreyPollutionData.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Preprocesamiento\n",
        "df = df.withColumnRenamed(\"PM2.5\", \"PM2_5\").withColumn(\"PM10\", col(\"PM10\").cast(DoubleType()))\n",
        "\n",
        "# Selecciona las variables relevantes y convierte PM10 a DoubleType\n",
        "df = df.select(['TOUT', 'WSR', 'PM10'])\n",
        "\n",
        "# Binariza PM10 para clasificación\n",
        "binarizer = Binarizer(threshold=10, inputCol=\"PM10\", outputCol=\"label\")\n",
        "df_bin = binarizer.transform(df)\n",
        "\n",
        "# Features para ambos modelos\n",
        "assembler = VectorAssembler(inputCols=['TOUT', 'WSR'], outputCol=\"features\")\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
        "\n",
        "# Regresión Lineal\n",
        "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"PM10\")\n",
        "\n",
        "# Clasificador Random Forest\n",
        "rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
        "\n",
        "# Pipeline de Regresión\n",
        "pipeline_reg = Pipeline(stages=[assembler, scaler, lr])\n",
        "\n",
        "# Pipeline de Clasificación\n",
        "pipeline_clf = Pipeline(stages=[assembler, scaler, rf])\n",
        "\n",
        "# Divide los datos para regresión y clasificación\n",
        "trainData_reg, testData_reg = df.randomSplit([0.7, 0.3], seed=42)\n",
        "trainData_clf, testData_clf = df_bin.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Entrenamiento y Predicción de Regresión\n",
        "model_reg = pipeline_reg.fit(trainData_reg)\n",
        "predictions_reg = model_reg.transform(testData_reg)\n",
        "\n",
        "# Evaluación de Regresión\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "print(f\"RMSE: {evaluator_rmse.evaluate(predictions_reg)}\")\n",
        "print(f\"R2: {evaluator_r2.evaluate(predictions_reg)}\")\n",
        "\n",
        "# Entrenamiento y Predicción de Clasificación\n",
        "model_clf = pipeline_clf.fit(trainData_clf)\n",
        "predictions_clf = model_clf.transform(testData_clf)\n",
        "\n",
        "# Evaluación de Clasificación\n",
        "evaluator_auc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "print(f\"AUC: {evaluator_auc.evaluate(predictions_clf)}\")\n",
        "print(f\"F1 Score: {evaluator_f1.evaluate(predictions_clf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnP3jS4VirEI",
        "outputId": "78165d75-f164-44e4-fd91-28627866f596"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 47.28759130209708\n",
            "R2: 0.04593140748951918\n",
            "AUC: 0.9886466848319708\n",
            "F1 Score: 0.9972809677615742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimento SIN Binarizacion**"
      ],
      "metadata": {
        "id": "Sj8fa0u9zLSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicia una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"CompletePollutionModeling\").getOrCreate()\n",
        "\n",
        "# Carga los datos\n",
        "df = spark.read.csv(\"/content/MonterreyPollutionData.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Preprocesamiento\n",
        "# Convierte PM10 a DoubleType si es necesario y renombra PM2.5 para evitar errores en la nomenclatura\n",
        "df = df.withColumn(\"PM10\", col(\"PM10\").cast(DoubleType())).withColumnRenamed(\"PM2.5\", \"PM2_5\")\n",
        "\n",
        "# Selecciona las variables relevantes incluyendo la variable objetivo PM10\n",
        "df = df.select(['PRS', 'RAINF', 'RH', 'SR', 'TOUT', 'WSR', 'WDV', 'PM10'])\n",
        "\n",
        "# Configuración de las características para el modelado\n",
        "# Aquí, asumimos que todas las variables excepto 'PM10' son las características de entrada\n",
        "featureCols = ['PRS', 'RAINF', 'RH', 'SR', 'TOUT', 'WSR', 'WDV']\n",
        "\n",
        "# VectorAssembler para combinar las columnas de características en una sola columna de vectores\n",
        "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n",
        "\n",
        "# StandardScaler para normalizar las características\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
        "\n",
        "# Modelo de Regresión Lineal\n",
        "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"PM10\")\n",
        "\n",
        "# Pipeline que incluye vectorización, escalado y regresión lineal\n",
        "pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "trainData, testData = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Entrenamiento del modelo con los datos de entrenamiento\n",
        "model = pipeline.fit(trainData)\n",
        "\n",
        "# Predicciones con el conjunto de prueba\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Evaluación del modelo con RMSE y R^2\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse = evaluator_rmse.evaluate(predictions)\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R2: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZX_a7wtqg9i",
        "outputId": "9c363356-7e64-4e63-9db8-dbde20e45dd5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 45.99305882153446\n",
            "R2: 0.06768320896762958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultados de Regresión**\n",
        "\n",
        "**Sin Binarizar:** RMSE = 45.993, R^2 = 0.067\n",
        "**Con Binarizar:** RMSE = 47.288, R^2 = 0.046"
      ],
      "metadata": {
        "id": "9bVgviFkwCXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparación de Regresión:**\n",
        "\n",
        "El modelo de regresión que utilizó todas las variables disponibles (PRS, RAINF, RH, SR, TOUT, WSR, WDV) **sin binarización** obtuvo un RMSE ligeramente menor y un R^2 ligeramente mayor en comparación con el modelo que solo usó TOUT y WSR con binarización.\n",
        "\n",
        "Esto sugiere que incluir una gama más amplia de variables no contaminantes puede ofrecer un modelo ligeramente más preciso y explicativo para predecir PM10, aunque la mejora es modesta. Esto indica que la complejidad del problema y la relación entre las variables independientes y PM10 puede no ser capturada completamente por los modelos lineales."
      ],
      "metadata": {
        "id": "Ib0ds1ILvu7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPERIMENTOS ADICIONALES // NO LINEALES**"
      ],
      "metadata": {
        "id": "U9qQ6IFrzUQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Suponiendo que 'spark' ya ha sido inicializado y 'df' cargado y preprocesado adecuadamente\n",
        "\n",
        "# Preprocesamiento\n",
        "df = df.withColumnRenamed(\"PM2.5\", \"PM2_5\").withColumn(\"PM10\", col(\"PM10\").cast(DoubleType()))\n",
        "\n",
        "# Selecciona las variables relevantes incluyendo la variable objetivo PM10\n",
        "df = df.select(['PRS', 'RAINF', 'RH', 'SR', 'TOUT', 'WSR', 'WDV', 'PM10'])\n",
        "\n",
        "# Configuración de las características para el modelado\n",
        "featureCols = ['PRS', 'RAINF', 'RH', 'SR', 'TOUT', 'WSR', 'WDV']\n",
        "\n",
        "# VectorAssembler para combinar las columnas de características en una sola columna de vectores\n",
        "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n",
        "\n",
        "# StandardScaler para normalizar las características\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
        "\n",
        "# Modelo de regresión no lineal: RandomForestRegressor\n",
        "rfRegressor = RandomForestRegressor(featuresCol=\"scaledFeatures\", labelCol=\"PM10\")\n",
        "\n",
        "# Pipeline que incluye vectorización, escalado y regresión con Random Forest\n",
        "pipeline = Pipeline(stages=[assembler, scaler, rfRegressor])\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "trainData, testData = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Entrenamiento del modelo con los datos de entrenamiento\n",
        "model = pipeline.fit(trainData)\n",
        "\n",
        "# Predicciones con el conjunto de prueba\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Evaluación del modelo con RMSE y R^2\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse = evaluator_rmse.evaluate(predictions)\n",
        "r2 = evaluator_r2.evaluate(predictions)\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R2: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOWLuKimrUCq",
        "outputId": "10b41114-6a98-484a-bc05-f5ce0fc7e751"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 42.50114421001552\n",
            "R2: 0.2038770147864758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Configurar el modelo Gradient-Boosted Trees\n",
        "gbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"PM10\", maxIter=10)\n",
        "\n",
        "# Pipeline que incluye vectorización, escalado y GBT\n",
        "pipeline_gbt = Pipeline(stages=[assembler, scaler, gbt])\n",
        "\n",
        "# Entrenamiento del modelo con los datos de entrenamiento\n",
        "model_gbt = pipeline_gbt.fit(trainData)\n",
        "\n",
        "# Predicciones con el conjunto de prueba\n",
        "predictions_gbt = model_gbt.transform(testData)\n",
        "\n",
        "# Evaluación del modelo GBT con RMSE y R^2\n",
        "evaluator_rmse_gbt = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_r2_gbt = RegressionEvaluator(labelCol=\"PM10\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse_gbt = evaluator_rmse_gbt.evaluate(predictions_gbt)\n",
        "r2_gbt = evaluator_r2_gbt.evaluate(predictions_gbt)\n",
        "\n",
        "print(f\"GBT RMSE: {rmse_gbt}\")\n",
        "print(f\"GBT R2: {r2_gbt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EarRqDqxwMNj",
        "outputId": "bbb1942b-1978-4607-fcae-b33bd1ca437b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBT RMSE: 45.95979185845792\n",
            "GBT R2: 0.06903141812330249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fzaffc5h1wff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}